{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3abae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d839d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir in python is used to get the list of all files and directories in the specified directory\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a24eb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\SHOURYA\\\\Documents\\\\Jupyter Notebooks\\\\TEXT dataset\\\\20_newsgroups'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b486caa50b54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Every folder of the 20 newsgroups which essentially are the different classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mfolders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_20_Classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\SHOURYA\\\\Documents\\\\Jupyter Notebooks\\\\TEXT dataset\\\\20_newsgroups'"
     ]
    }
   ],
   "source": [
    "# Getting the list of the 20 directories that exist in folder 20_newsgroups provided in the dataset using listdir \n",
    "path_to_20_Classes = r\"C:\\Users\\SHOURYA\\Documents\\Jupyter Notebooks\\TEXT dataset\\20_newsgroups\"\n",
    "\n",
    "\n",
    "#Every folder of the 20 newsgroups which essentially are the different classes\n",
    "folders = listdir(path_to_20_Classes)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cabd7a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d87b1d90610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcurrent_folder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m:\u001b[0m                \u001b[1;31m#Selecting one of the 20 folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mfolder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_20_Classes\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcurrent_folder\u001b[0m   \u001b[1;31m#Path to each file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfiles_in_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folders' is not defined"
     ]
    }
   ],
   "source": [
    "#This will contain the path of every one of the 20000 files in the 20 newsgroups\n",
    "file_path = []\n",
    "\n",
    "\n",
    "for current_folder in folders:                #Selecting one of the 20 folders\n",
    "    folder_path = path_to_20_Classes + '\\\\' + current_folder   #Path to each file\n",
    "    files_in_folder = listdir(folder_path)        \n",
    "    class_wise_address = []                   #Storing the address class wise\n",
    "    for single_file in files_in_folder:       #Selecting one of the 1000 files\n",
    "        new_path = folder_path + '\\\\' + single_file     #Giving each file a path\n",
    "        class_wise_address.append(new_path)             #Storing the paths of each file\n",
    "    file_path.append(class_wise_address)                #Storing the paths class wise in a 2D list\n",
    "\n",
    "    \n",
    "(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140c49fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fcea7de4627e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#nltk.download('stopwords')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Stopwords are the English words which does not add much meaning to a sentence.\n",
    "#They can safely be ignored without sacrificing the meaning of the sentence. \n",
    "#For example, the words like the, he, have etc. \n",
    "#Such words are already captured this in corpus named corpus.\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa686cdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2fa58b6cf1ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Taking only the English stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\SHOURYA/nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\SHOURYA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#Taking only the English stopwords\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8550a3eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LazyCorpusLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bbfe9e9bf85a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Examples of stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'LazyCorpusLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#Examples of stopwords\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a5000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Python module re provides full support for Perl-like regular expressions in Python. \n",
    "#The re module raises the exception re.error if an error occurs while compiling or using a regular expression\n",
    "import re\n",
    "\n",
    "#dictionary to store the count of words and would eventually help in finding the probablities\n",
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8c2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In every class\n",
    "for class_files in file_path:\n",
    "    #In all class files\n",
    "    for single_file in class_files:\n",
    "        #In every file\n",
    "        file = open(single_file)\n",
    "        file_read = file.read()\n",
    "        \n",
    "        #Splitting to obtain every single word in the 20000 files\n",
    "        for each_word in re.split(r\"[^abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ]\",file_read):\n",
    "            word = each_word.lower()\n",
    "            if word not in stopwords:      #Checking to see if the word is a stopword or not since it does not help in classifying\n",
    "                \n",
    "                if word in dictionary:\n",
    "                    dictionary[word] += 1   #If word already is in dictionary, we increase its count\n",
    "                else:\n",
    "                    dictionary[word] = 1       #Else a new key is created\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc65c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of words in the dictionary\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29ee7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07318578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the dictionary in reverse order according to the count of words\n",
    "dictionary_sorted = sorted(dictionary.items(), key = lambda x: x[1], reverse = True)  #lambda is an anonymous function which returns one expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0104af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accdf652",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5bf73d5079eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Blank space is of no use to us\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mdictionary_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "#Blank space is of no use to us\n",
    "del dictionary_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a1e50a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = dictionary_sorted\n",
    "feature_words = []\n",
    "feature_count = []\n",
    "for i in range(len(features)):\n",
    "    feature_words.append(i)\n",
    "    feature_count.append(features[i][1])\n",
    "plt.plot(feature_words,feature_count)\n",
    "plt.xlabel(\"words ->\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.grid()\n",
    "plt.axis([0,10000,1,5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461aac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting words that are not necessarily useful in predicting the classes\n",
    "del dictionary_sorted[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e28b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our datasets\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988680fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary to store all the words that we are going to use\n",
    "word_list = {}\n",
    "count = 0\n",
    "\n",
    "for i in dictionary_sorted:\n",
    "    \n",
    "    word_list[i[0]] = count    #The words are indexed from 0 to 9000\n",
    "    count += 1\n",
    "\n",
    "print(len(word_list))\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b40238a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7c348449430a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcurrent_class_number\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m      \u001b[1;31m#Picking each class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_class_number\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m     \u001b[1;31m#Picking all the files in a particular class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#List to store the word count of a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcurrent_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for current_class_number in range(20):      #Picking each class\n",
    "    for files in file_path[current_class_number]:     #Picking all the files in a particular class\n",
    "        \n",
    "        #List to store the word count of a file\n",
    "        current_x = [0 for i in range(len(word_list))]   \n",
    "        single_file = open(files)\n",
    "        fread = single_file.read()\n",
    "        for word in re.split(r\"[^abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ]\", fread):\n",
    "            #picking every word and using the lower case version\n",
    "            word = word.lower()\n",
    "            if word in word_list:\n",
    "                \n",
    "                #If the word is present in the file, we increment its count\n",
    "                current_x[word_list[word]] += 1\n",
    "        x.append(current_x)                        #Append the files in our X\n",
    "        y.append(current_class_number)             #Append the class number of our file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a2a3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the x and y to numpy arrays to help in further evaluation\n",
    "x = np.array(x)\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e6d7843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f156a0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36951cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aa252cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-6126f50d609c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[0;32m   2176\u001b[0m                                               default_test_size=0.25)\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1857\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1858\u001b[0m             \u001b[1;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fd1fbee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bbc6d6dca0eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0800c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Classification using Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#To check accuracy of our results\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cd1a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the multionomial Naive Bayes Classifier\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2f5a1e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-69453cb9dd17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Fitting Our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Fitting Our model\n",
    "clf.fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29b0cd35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b0972710762b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predictions on test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Predictions on test set\n",
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1a9cab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d37722fda799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score on training data:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score on testing data:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Score on training data:\",clf.score(X_train, Y_train))\n",
    "print(\"Score on testing data:\",clf.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4e7d342",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-48df449b42d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f13af717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, Y_train):\n",
    "    result = {}; \n",
    "    \n",
    "    #class_values are the unique values in Y_train, and counts stores their count in the list\n",
    "    class_values, counts = np.unique(Y_train, return_counts=True)\n",
    "    \n",
    "    result[\"total_data\"] = len(Y_train)  #Total files in our data\n",
    "    #picking each class in our data\n",
    "    for current_class in range(len(class_values)):\n",
    "        result[current_class] = {}   \n",
    "        \n",
    "        #Picking only those rows which output the current class\n",
    "        current_class_rows = (Y_train == current_class)\n",
    "        X_train_current_class = X_train[current_class_rows]    #Rows in X_train with current class output\n",
    "        Y_train_current_class = Y_train[current_class_rows]    #Rows in Y_train with current class output\n",
    "        result[current_class][\"total_count\"] = counts[current_class]   #Count of the files of our current class\n",
    "        \n",
    "        total_words = 0\n",
    "        for j in word_list:\n",
    "            #We'll pick the column in our X_train(of current class) which has the current word and sum it across the rows\n",
    "            result[current_class][word_list[j]] = (X_train_current_class[:, word_list[j]]).sum()  \n",
    "            total_words += result[current_class][word_list[j]]   \n",
    "        \n",
    "        result[current_class][\"total_words\"] = total_words    #Total number of a particular word in our class\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f1c90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For calculating the probability of finding the paticular word for a file\n",
    "def probability(res, x, curr_class):\n",
    "    \n",
    "    #We take the log probability so that the probabilities don't multiply up to zero\n",
    "    ans = np.log(res[curr_class][\"total_count\"]) - np.log(res[\"total_data\"])\n",
    "    \n",
    "    #No., of features is just the total number of words we'll use\n",
    "    num_features = len(word_list)\n",
    "    for i in range(num_features):\n",
    "        xi = x[i] \n",
    "        if(xi != 0):     #If the word is present\n",
    "            \n",
    "            curr_class_count_xi = xi * res[curr_class][i] + 1\n",
    "            curr_class_count = res[curr_class][\"total_words\"] + len(word_list)\n",
    "            \n",
    "            #Formula of probability = count of word in current class / count of all words in the class\n",
    "            ans += np.log(curr_class_count_xi) - np.log(curr_class_count)   \n",
    "    return ans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ec40d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For predicting the probabities of every single file which would then be multiplied to get final probability\n",
    "def predictSinglePoint(res, x):\n",
    "    \n",
    "    #The classes are the keys of our dictionary\n",
    "    classes = res.keys()\n",
    "    \n",
    "    #We can initialise like this but I am using bool First run method to avoid it\n",
    "#     best_p = -1000\n",
    "#     best_class = -1\n",
    "    first_run = True\n",
    "    \n",
    "    for curr_class in classes:\n",
    "        \n",
    "        #This is an extra key we added to know the total data count\n",
    "        if(curr_class == \"total_data\"):\n",
    "            continue\n",
    "        \n",
    "        #Calculating the probability of every class and finding the best one\n",
    "        y = probability( res, x, curr_class)\n",
    "        if(first_run or (y >= best_p)):\n",
    "            best_p = y\n",
    "            best_class = curr_class  #If the probability of a class is higher, that will be our answer\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa7d19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(res, X_test):\n",
    "    \n",
    "    #List to store our predictions\n",
    "    Y_pred = []\n",
    "    \n",
    "    for x in X_test:\n",
    "        \n",
    "        #predicting each file\n",
    "        y = predictSinglePoint(res, x)\n",
    "        \n",
    "        #Storing the class\n",
    "        Y_pred.append(y)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "543b2998",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-85ba0ceb69d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Fitting the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresulting_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Fitting the model\n",
    "resulting_dict = fit(X_train, Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cad7907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resulting_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6b3a818533f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predicting the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresulting_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'resulting_dict' is not defined"
     ]
    }
   ],
   "source": [
    "#Predicting the output\n",
    "Y_pred_test = predict(resulting_dict, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "beb12a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-73462ff039cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Accuracy obtained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Accuracy obtained\n",
    "accuracy_score(Y_test, Y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1ad9b15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-0e87e0204172>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,Y_pred_test))\n",
    "print(classification_report(Y_test,Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48d9a87f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-764e8112c2fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of the sklearn model = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy of the Self Implementation model = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the sklearn model = \", clf.score(X_test, Y_test))\n",
    "print(\"Accuracy of the Self Implementation model = \", accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a1d7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
